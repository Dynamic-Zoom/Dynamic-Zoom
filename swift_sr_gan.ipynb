{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import cudacanvas\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swift SRGAN model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (initial): ConvBlock(\n",
       "    (cnn): SeperableConv2d(\n",
       "      (depthwise): Conv2d(3, 3, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=3)\n",
       "      (pointwise): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (bn): Identity()\n",
       "    (act): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (residual): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (8): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (9): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (10): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualBlock(\n",
       "      (block1): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "      (block2): ConvBlock(\n",
       "        (cnn): SeperableConv2d(\n",
       "          (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=64)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (convblock): ConvBlock(\n",
       "    (cnn): SeperableConv2d(\n",
       "      (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (upsampler): Sequential(\n",
       "    (0): UpsampleBlock(\n",
       "      (conv): SeperableConv2d(\n",
       "        (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
       "        (pointwise): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (ps): PixelShuffle(upscale_factor=2)\n",
       "      (act): PReLU(num_parameters=64)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): SeperableConv2d(\n",
       "    (depthwise): Conv2d(64, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=64)\n",
       "    (pointwise): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SeperableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1, bias=True):\n",
    "        super(SeperableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride = stride,\n",
    "            groups=in_channels,\n",
    "            bias=bias,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels, \n",
    "            kernel_size=1,\n",
    "            bias=bias\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "    \n",
    "\n",
    "    \n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_act=True, use_bn=True, discriminator=False, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.use_act = use_act\n",
    "        self.cnn = SeperableConv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) if discriminator else nn.PReLU(num_parameters=out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        \n",
    "        self.conv = SeperableConv2d(in_channels, in_channels * scale_factor**2, kernel_size=3, stride=1, padding=1)\n",
    "        self.ps = nn.PixelShuffle(scale_factor) # (in_channels * 4, H, W) -> (in_channels, H*2, W*2)\n",
    "        self.act = nn.PReLU(num_parameters=in_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))\n",
    "        \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block1 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1\n",
    "        )\n",
    "        self.block2 = ConvBlock(\n",
    "            in_channels,\n",
    "            in_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            use_act=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        return out + x\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Swift-SRGAN Generator\n",
    "    Args:\n",
    "        in_channels (int): number of input image channels.\n",
    "        num_channels (int): number of hidden channels.\n",
    "        num_blocks (int): number of residual blocks.\n",
    "        upscale_factor (int): factor to upscale the image [2x, 4x, 8x].\n",
    "    Returns:\n",
    "        torch.Tensor: super resolution image\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int = 3, num_channels: int = 64, num_blocks: int = 16, upscale_factor: int = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n",
    "        self.residual = nn.Sequential(\n",
    "            *[ResidualBlock(num_channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n",
    "        self.upsampler = nn.Sequential(\n",
    "            *[UpsampleBlock(num_channels, scale_factor=2) for _ in range(upscale_factor//2)]\n",
    "        )\n",
    "        self.final_conv = SeperableConv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residual(initial)\n",
    "        x = self.convblock(x) + initial\n",
    "        x = self.upsampler(x)\n",
    "        return (torch.tanh(self.final_conv(x)) + 1) / 2\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Swift-SRGAN Discriminator\n",
    "    Args:\n",
    "        in_channels (int): number of input image channels.\n",
    "        features (tuple): sequence of hidden channels.\n",
    "    Returns:\n",
    "        torch.Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 3,\n",
    "        features: tuple = (64, 64, 128, 128, 256, 256, 512, 512),\n",
    "    ) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(\n",
    "                    in_channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + idx % 2,\n",
    "                    padding=1,\n",
    "                    discriminator=True,\n",
    "                    use_act=True,\n",
    "                    use_bn=False if idx == 0 else True,\n",
    "                )\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.blocks(x)\n",
    "        return torch.sigmoid(self.classifier(x))\n",
    "\n",
    "upscale_factor = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Generator(upscale_factor=upscale_factor).to(device)\n",
    "\n",
    "# Load model weigths\n",
    "# torch.load(\"swift_srgan_4x\")\n",
    "    \n",
    "model.load_state_dict(torch.load(\"swift_srgan_2x.pth.tar\")['model'])\n",
    "model.eval()\n",
    "# Print number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get cursor position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse callback function to update cursor position\n",
    "def update_cursor_position(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x, cursor_y = x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform to be applied to frames\n",
    "# Currently only transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def upscale_video(video_path, model, transform = None, out_video_path = None, evaluate_mode = False):\n",
    "    \"\"\"\n",
    "    Upscale a video 3x by using bicubic plus plus model\n",
    "    - video_path: path to the video\n",
    "    - model: bicubic plus plus model\n",
    "    - transform: transform to be applied to frames\n",
    "    - out_video_path: path to the output video (only if evaluate_mode is True)\n",
    "    - evaluate_mode: if True, model is used to write the video to storage so that it can be evaluated.\n",
    "    - evaluate mode is slow due to GPu -> CPU transfer overhead\n",
    "\n",
    "    - Output: Upscaled Video feed or File storage if in evaluate mode \n",
    "    \"\"\"\n",
    "    # Set CUDA device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_width*upscale_factor, frame_height*upscale_factor))\n",
    "\n",
    "\n",
    "    # Set up cudacanvas window for renders\n",
    "    if not evaluate_mode:\n",
    "        white_screen = torch.ones((3, int(frame_height/6*upscale_factor), int(frame_width/6*upscale_factor))).to(device)\n",
    "        cudacanvas.set_image(white_screen)\n",
    "        cudacanvas.create_window()\n",
    "\n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        elapsed_time = 0\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_downsampled = cv2.resize(frame, (int(frame.shape[1] / 6), int(frame.shape[0] / 6))) \n",
    "        \n",
    "        # Convert frame to RGB and apply transform\n",
    "        frame_rgb = frame_downsampled\n",
    "        frame_rgb = cv2.cvtColor(frame_rgb, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        frame_bicubic = cv2.resize(frame_rgb, (frame_downsampled.shape[1] * upscale_factor, frame_downsampled.shape[0] * upscale_factor))\n",
    "        # frame_bicubic = cv2.cvtColor(frame_bicubic, cv2.COLOR_BGR2RGB)\n",
    "        frame_bicubic = transform(frame_bicubic).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_tensor = model(frame_tensor)\n",
    "            upscaled_frame_tensor = torch.clamp(upscaled_frame_tensor, 0, 1)\n",
    "            # print(frame_downsampled.shape, frame_bicubic.shape, frame_tensor.shape, upscaled_frame_tensor.shape)\n",
    "        \n",
    "        # print(frame_downsampled.shape, frame_bicubic.shape, frame_tensor.shape, upscaled_frame_tensor.shape)\n",
    "        \n",
    "        # Write the upscaled frame to output video file if in evaluate mode\n",
    "        if evaluate_mode:\n",
    "            # Convert tensor back to numpy array\n",
    "            upscaled_frame = (upscaled_frame_tensor.squeeze().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "            upscaled_frame = cv2.cvtColor(upscaled_frame, cv2.COLOR_RGB2BGR)\n",
    "            # cv2.imshow('Upscaled Frame', upscaled_frame)\n",
    "            # # Write upscaled frame to output video\n",
    "            output_video.write(upscaled_frame)\n",
    "        \n",
    "        # If no evaluation, just output using cudacanvas\n",
    "        else:\n",
    "            cudacanvas.render()\n",
    "            # Concatenate frame and upscaled frame\n",
    "            combine = torch.concat([frame_bicubic, upscaled_frame_tensor], dim = -1)\n",
    "            cudacanvas.set_image(upscaled_frame_tensor.squeeze())\n",
    "            if cudacanvas.should_close():\n",
    "                break\n",
    "        \n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        if evaluate_mode:\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# testing\n",
    "video_path = 'test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4' \n",
    "upscale_video(video_path, model, transform = transform, evaluate_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average FPS for 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input frame size = torch.Size([1, 3, 180, 270])\n",
      "Output frame size = torch.Size([1, 3, 720, 1080])\n",
      "Average Time per frame = 130.43982982635498 ms\n",
      "Average FPS = 7.666370013907768 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 3, 180, 270).to(device)\n",
    "times = []\n",
    "for i in tqdm(range(10)):\n",
    "  torch.cuda.synchronize()\n",
    "  start = time.time()\n",
    "  with torch.no_grad():\n",
    "    pred = model(noise)\n",
    "    pred = torch.clamp(pred, 0, 1)\n",
    "  torch.cuda.synchronize()\n",
    "  end = time.time() - start\n",
    "  times.append(end)\n",
    "\n",
    "# plt.imshow(pred.squeeze().cpu().numpy().transpose(1, 2, 0))\n",
    "avg_time = np.mean(times)\n",
    "\n",
    "print(\"Input frame size =\", noise.shape)\n",
    "print(\"Output frame size =\", pred.shape)\n",
    "print(\"Average Time per frame =\", 1000*avg_time, \"ms\")\n",
    "print(\"Average FPS =\", 1/avg_time, \"FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Timings\n",
    "- Uncomment each line to test individual transfer latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 66.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time (ms): 15.644576814439562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "tot_time = 0\n",
    "\n",
    "# input tensor (360p)\n",
    "frame_tensor_cpu = torch.randn(1,3,960,720)\n",
    "frame_tensor_gpu = frame_tensor_cpu.to('cuda')\n",
    "frame_tensor_cpu_3x = torch.randn(1,3,2160,3840)\n",
    "frame_tensor_gpu_3x = frame_tensor_cpu_3x.to('cuda')\n",
    "frame_tensor_shared = frame_tensor_cpu_3x.pin_memory()\n",
    "shared_ref = torch.zeros(1,3,2160,3840).pin_memory()\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    st = time.time()\n",
    "    # frame_tensor_cpu.to('cuda') # 1.4 ms - normal cpu to gpu / 24.240\n",
    "    # frame_tensor_shared.to('cuda') # 9 ms - pinned cpu to gpu\n",
    "    # shared_ref[:] = frame_tensor_cpu_3x # 14.26 ms - normal cpu to pinned cpu\n",
    "    # shared_ref[:] = frame_tensor_gpu_3x # 8.07 ms - gpu to pinned cpu\n",
    "    # shared_ref.to('cpu') # 0.001 ms\n",
    "    frame_tensor_gpu_3x.to('cpu') # 16.12 ms - gpu to normal cpu\n",
    "    \n",
    "    tot_time += time.time() - st\n",
    "print('Average time (ms):', tot_time/i*1000)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Metrics\n",
    "- PSNR\n",
    "- SSIM\n",
    "- Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties:\n",
      "Frame width: 3840\n",
      "Frame height: 2160\n",
      "FPS: 30.00101354775499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_2844\\1428699725.py:102: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
      "  psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.06864156491552 45.62586493401043 0.8491064791095337 0.9779791921613245 0.0 0.8649909496307373\n",
      "47.793950782489816 43.3488291220111 0.8788903816684389 0.9690509909448076 0.0 0.62111496925354\n",
      "52.567150326890264 48.10033902759245 0.8416854126756786 0.9776448964695726 0.0 0.6278104782104492\n",
      "46.97751226341669 42.23897639133946 0.8355417269577662 0.9458024114258546 0.0 0.6323878765106201\n",
      "50.427247804790966 46.697468405610195 0.8378131971088335 0.9831677276174764 0.0 0.6334424018859863\n",
      "Average PSNR (bicubic): 49.36690054850065\n",
      "Average PSNR (SR): 45.202295576112725\n",
      "Average SSIM (bicubic): 0.8486074395040502\n",
      "Average SSIM (SR): 0.9707290437238072\n",
      "Average inference time (bicubic): 0.0\n",
      "Average inference time (SR): 0.6759493350982666\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def evaluate_model(video_path, model, crop_size = [1920, 1080], upscale_factor = 3, n_samples = 10, transform = None):\n",
    "    \"\"\"\n",
    "    - This function samples a random area of 'crop_size' from the video. \n",
    "    - This is then downsampled by 3x and then upscaled back to 'crop_size'\n",
    "    - This is then compared to the original cropped frame\n",
    "    - The baseline is the regular bicubic upsampling\n",
    "\n",
    "    Inputs:\n",
    "    - video_path: path to the test 4k video\n",
    "    - model: Super res model\n",
    "    - n_samples: number of samples to evaluate\n",
    "    - transform: transform to use\n",
    "\n",
    "    Outputs:\n",
    "    - PSNR: Average Peak Signal to Noise Ratio\n",
    "    - SSIM: Average Structural Similarity Index\n",
    "    - infer_time: Average inference time\n",
    "    \"\"\"\n",
    "    # Get device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(\"Video properties:\")\n",
    "    print(\"Frame width:\", frame_width)\n",
    "    print(\"Frame height:\", frame_height)\n",
    "    print(\"FPS:\", fps)\n",
    "\n",
    "    # Read and process n_samples of frames\n",
    "    n = 0\n",
    "    psnr_bicubic_list = []\n",
    "    psnr_sr_list = []\n",
    "    ssim_bicubic_list = []\n",
    "    ssim_sr_list = []\n",
    "    infer_time_bicubic_list = []\n",
    "    infer_time_sr_list = []\n",
    "\n",
    "    while True and n < n_samples:\n",
    "        # Read frame \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if np.amax(frame) == 0 and np.amin(frame) == 0:\n",
    "            continue\n",
    "        n += 1\n",
    "        # if n == 1:\n",
    "        #     continue\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        crop_width, crop_height = crop_size\n",
    "        # Get cropped region of frame\n",
    "        x_start = random.randint(0, frame_width - crop_width)\n",
    "        y_start = random.randint(0, frame_height - crop_height)\n",
    "        x_end = x_start + crop_width\n",
    "        y_end = y_start + crop_height\n",
    "\n",
    "        \n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Downsample frame\n",
    "        downsampled_frame = cv2.resize(cropped_frame, (int(cropped_frame.shape[1] / upscale_factor), int(cropped_frame.shape[0] / upscale_factor)))\n",
    "\n",
    "        # Upsample frame\n",
    "        torch.cuda.synchronize()\n",
    "        time.time()\n",
    "        upscaled_frame_bicubic = cv2.resize(downsampled_frame, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_bicubic = time.time() - time.time()\n",
    "        # print(frame.shape, cropped_frame.shape, downsampled_frame.shape, upscaled_frame_bicubic.shape)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(downsampled_frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_sr = time.time() - start\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_bicubic = compare_psnr(cropped_frame, upscaled_frame_bicubic)\n",
    "        psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n",
    "\n",
    "        # Calculate SSIM\n",
    "        ssim_bicubic = compare_ssim(cropped_frame, upscaled_frame_bicubic, channel_axis=-1, data_range=1, multichannel=True)\n",
    "        ssim_sr = compare_ssim(cropped_frame/255, upscaled_frame_sr, channel_axis=-1, data_range=1, multichannel=True)\n",
    "\n",
    "        print(psnr_bicubic, psnr_sr, ssim_bicubic, ssim_sr, infer_time_bicubic, infer_time_sr)\n",
    "\n",
    "        psnr_bicubic_list.append(psnr_bicubic)\n",
    "        psnr_sr_list.append(psnr_sr)\n",
    "        ssim_bicubic_list.append(ssim_bicubic)\n",
    "        ssim_sr_list.append(ssim_sr)\n",
    "        infer_time_bicubic_list.append(infer_time_bicubic)\n",
    "        infer_time_sr_list.append(infer_time_sr)\n",
    "\n",
    "        # Display the upscaled frame by concatenating the original and upscaled frames\n",
    "        # top = np.concatenate((cropped_frame/255, cropped_frame/255), axis=1)\n",
    "        # bottom = np.concatenate((upscaled_frame_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        # combined = np.concatenate((top, bottom), axis=0)\n",
    "        # cv2.imshow('frame', combined)\n",
    "        \n",
    "        # # cv2.imshow('frame', upscaled_frame_sr)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "        \n",
    "\n",
    "    # Calculate average PSNR and SSIM only for values that are not Nan or Inf\n",
    "    psnr_bicubic_list = [psnr for psnr in psnr_bicubic_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    psnr_sr_list = [psnr for psnr in psnr_sr_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    ssim_bicubic_list = [ssim for ssim in ssim_bicubic_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    ssim_sr_list = [ssim for ssim in ssim_sr_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    infer_time_bicubic_list = [infer_time for infer_time in infer_time_bicubic_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "    infer_time_sr_list = [infer_time for infer_time in infer_time_sr_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "\n",
    "    avg_psnr_bicubic = np.mean(psnr_bicubic_list)\n",
    "    avg_psnr_sr = np.mean(psnr_sr_list)\n",
    "    avg_ssim_bicubic = np.mean(ssim_bicubic_list)\n",
    "    avg_ssim_sr = np.mean(ssim_sr_list)\n",
    "    avg_infer_time_bicubic = np.mean(infer_time_bicubic_list)\n",
    "    avg_infer_time_sr = np.mean(infer_time_sr_list)\n",
    "\n",
    "\n",
    "    return avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr\n",
    "\n",
    "\n",
    "video_path = \"./test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4\"\n",
    "avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr = evaluate_model(video_path, model, transform=transform, n_samples=5\n",
    "                                                                                                                         , crop_size=[1920,1080], upscale_factor=2)        \n",
    "print(\"Average PSNR (bicubic):\", avg_psnr_bicubic)\n",
    "print(\"Average PSNR (SR):\", avg_psnr_sr)\n",
    "print(\"Average SSIM (bicubic):\", avg_ssim_bicubic)\n",
    "print(\"Average SSIM (SR):\", avg_ssim_sr)\n",
    "print(\"Average inference time (bicubic):\", avg_infer_time_bicubic)\n",
    "print(\"Average inference time (SR):\", avg_infer_time_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample image for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./test_videos/2022-Formula1-Aston-Martin-AMR22-006-2160.jpg\"\n",
    "img_path = \"test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4\"\n",
    "# image = cv2.imread(img_path)\n",
    "cap = cv2.VideoCapture(img_path)\n",
    "\n",
    "cursor_x = -1\n",
    "cursor_y = -1\n",
    "drawing = False\n",
    "\n",
    "# Mouse callback function\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x = x\n",
    "        cursor_y = y\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "\n",
    "cv2.namedWindow('BBoxWindow')\n",
    "cv2.namedWindow('Cropped frame')\n",
    "# cv2.namedWindow(\"SR Window\")\n",
    "cv2.setMouseCallback('BBoxWindow', mouse_callback)\n",
    "\n",
    "bb_size = [270,180]\n",
    "cropped_image_bicubic = np.zeros((bb_size[1]*4, bb_size[0]*4, 3))\n",
    "combined = np.zeros((bb_size[1]*4*2, bb_size[0]*4, 3))\n",
    "upscaled_frame_sr = np.zeros((bb_size[1]*4, bb_size[0]*4, 3))\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    # image = cv2.resize(image, (1920,1080))\n",
    "    if not ret:\n",
    "        break\n",
    "    # Draw bounding box based on cursor position\n",
    "    if cursor_x != -1 and cursor_y != -1:\n",
    "        # top_left = (max(0,cursor_x - bb_size[0]//2), max(0,cursor_y - bb_size[1]//2))\n",
    "        # bottom_right = (min(image.shape[0],cursor_x + bb_size[0]//2), min(image.shape[1], cursor_y + bb_size[1]//2))\n",
    "        \n",
    "        top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "        bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "        \n",
    "        # crop image only for the bounding box region\n",
    "        if top_left[0] >= 0 and top_left[1] >= 0 and bottom_right[0] < image.shape[1] and bottom_right[1] < image.shape[0]:\n",
    "            cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            cropped_image_bicubic = cv2.resize(cropped_image, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Stack horizontally\n",
    "        combined = np.concatenate((cropped_image_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        \n",
    "        # image_copy = image.copy()\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Cropped frame', combined)\n",
    "    cv2.imshow(\"SR Window\", upscaled_frame_sr)\n",
    "    \n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./test_videos/2022-Formula1-Aston-Martin-AMR22-006-2160.jpg\"\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "cursor_x = -1\n",
    "cursor_y = -1\n",
    "save = False\n",
    "\n",
    "# Mouse callback function\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x = x\n",
    "        cursor_y = y\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        save = True\n",
    "\n",
    "cv2.namedWindow('BBoxWindow')\n",
    "cv2.namedWindow('Result frame')\n",
    "# cv2.namedWindow(\"SR Window\")\n",
    "cv2.setMouseCallback('BBoxWindow', mouse_callback)\n",
    "\n",
    "while True:\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # Draw bounding box based on cursor position\n",
    "    if cursor_x != -1 and cursor_y != -1:\n",
    "        # top_left = (max(0,cursor_x - bb_size[0]//2), max(0,cursor_y - bb_size[1]//2))\n",
    "        # bottom_right = (min(image.shape[0],cursor_x + bb_size[0]//2), min(image.shape[1], cursor_y + bb_size[1]//2))\n",
    "        \n",
    "        top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "        bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "        \n",
    "        # crop image only for the bounding box region\n",
    "        if top_left[0] >= 0 and top_left[1] >= 0 and bottom_right[0] < image.shape[1] and bottom_right[1] < image.shape[0]:\n",
    "            cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            cropped_image_bicubic = cv2.resize(cropped_image, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Stack horizontally\n",
    "        combined = np.concatenate((cropped_image_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        \n",
    "        # image_copy = image.copy()\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Cropped frame', combined)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = \"test_videos/test_image.jpg\"\n",
    "img_path = \"test_videos/input_image.png\"\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# Get ROI\n",
    "# For basket ball image\n",
    "# cursor_x = 877\n",
    "# cursor_y = 202\n",
    "\n",
    "# bb_size = [540,360]\n",
    "\n",
    "# For Bird image\n",
    "cursor_x = 650\n",
    "cursor_y = 252\n",
    "\n",
    "bb_size = [135,90]\n",
    "\n",
    "top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "\n",
    "cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "cropped_image_bicubic = cv2.resize(cropped_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Convert frame to tensor\n",
    "frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    upscaled_frame_sr = model(frame_tensor)\n",
    "    upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "# Convert tensor back to numpy array\n",
    "upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# image_copy = image.copy()\n",
    "cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"Results/bird_frame.jpg\", image)\n",
    "cv2.imwrite(\"Results/bird_cropped_frame.jpg\", cropped_image)\n",
    "# cv2.imwrite(\"Results/bird_bicubic_frame.jpg\", (cropped_image_bicubic).astype(np.uint8))\n",
    "cv2.imwrite(\"Results/bird_upscaled_frame_sr_swift_sr_gan.jpg\", (upscaled_frame_sr*255).astype(np.uint8))\n",
    "\n",
    "while True:\n",
    "    # Display the imageq\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Result frame', upscaled_frame_sr)\n",
    "    cv2.imshow('Bicubic frame', cropped_image_bicubic)\n",
    "\n",
    "    \n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "766-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
