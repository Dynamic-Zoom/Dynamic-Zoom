{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import cudacanvas\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bicubic Plus Plus Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bicubic_plus_plus(\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv_out): Conv2d(32, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (Depth2Space): PixelShuffle(upscale_factor=6)\n",
       "  (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bicubic_plus_plus(nn.Module):\n",
    "    \"\"\"\n",
    "    Bicuic Plus Plus model. Adapted from Aselsan Researach group.\n",
    "    - Pretrained weights from their github repository.\n",
    "    - https://github.com/aselsan-research-imaging-team/bicubic-plusplus \n",
    "    \"\"\"\n",
    "    def __init__(self, sr_rate=3):\n",
    "        super(Bicubic_plus_plus, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_out = nn.Conv2d(32, (2*sr_rate)**2 * 3, kernel_size=3, padding=1, bias=False)\n",
    "        self.Depth2Space = nn.PixelShuffle(2*sr_rate)\n",
    "        self.act = nn.LeakyReLU(inplace=True, negative_slope=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv0(x)\n",
    "        x0 = self.act(x0)\n",
    "        x1 = self.conv1(x0)\n",
    "        x1 = self.act(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.act(x2) + x0\n",
    "        y = self.conv_out(x2)\n",
    "        y = self.Depth2Space(y)\n",
    "        return y\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Bicubic_plus_plus().to(device)\n",
    "model.load_state_dict(torch.load('weights/bicubic_pp_x3.pth'))\n",
    "model.eval()\n",
    "# Print number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering FPS: 22.389583153137497\n",
      "Original FPS: 25.0\n",
      "Video Length: 15.16 seconds\n",
      "Original Video Length: 15.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define transform to be applied to frames\n",
    "# Currently only transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def upscale_video(video_path, model, transform = None, out_video_path = None, evaluate_mode = False):\n",
    "    \"\"\"\n",
    "    Upscale a video 3x by using bicubic plus plus model\n",
    "    - video_path: path to the video\n",
    "    - model: bicubic plus plus model\n",
    "    - transform: transform to be applied to frames\n",
    "    - out_video_path: path to the output video (only if evaluate_mode is True)\n",
    "    - evaluate_mode: if True, model is used to write the video to storage so that it can be evaluated.\n",
    "    - evaluate mode is slow due to GPu -> CPU transfer overhead\n",
    "\n",
    "    - Output: Upscaled Video feed or File storage if in evaluate mode \n",
    "    \"\"\"\n",
    "    # Set CUDA device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_time = 1.0 / fps\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_width*3, frame_height*3))\n",
    "\n",
    "    # Set up cudacanvas window for renders\n",
    "    white_screen = torch.ones((3, frame_height*3, frame_width*3)).to(device)\n",
    "    cudacanvas.set_image(white_screen)\n",
    "    cudacanvas.create_window()\n",
    "    \n",
    "    times = []  # List to store time taken to process each frame\n",
    "    prev_time = time.time()\n",
    "    # Initialize variables for moving average calculation\n",
    "    moving_avg_duration = 0\n",
    "    alpha = 0.3  # Smoothing factor for moving average, adjust as needed\n",
    "    frame_time = 1.0 / fps\n",
    "\n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to RGB and apply transform\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_tensor = model(frame_tensor)\n",
    "            upscaled_frame_tensor = torch.clamp(upscaled_frame_tensor, 0, 1)\n",
    "        \n",
    "        # Write the upscaled frame to output video file if in evaluate mode\n",
    "        if evaluate_mode:\n",
    "            # Convert tensor back to numpy array\n",
    "            upscaled_frame = (upscaled_frame_tensor.squeeze().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "            upscaled_frame = cv2.cvtColor(upscaled_frame, cv2.COLOR_RGB2BGR)\n",
    "            # # Write upscaled frame to output video\n",
    "            output_video.write(upscaled_frame)\n",
    "        \n",
    "        # If no evaluation, just output using cudacanvas\n",
    "        else:\n",
    "            start_time = time.time()\n",
    "            cudacanvas.render()\n",
    "            cudacanvas.set_image(upscaled_frame_tensor.squeeze())\n",
    "            render_time = time.time() - start_time\n",
    "            # Update moving average of frame processing time\n",
    "            moving_avg_duration = (alpha * render_time) + ((1 - alpha) * moving_avg_duration)\n",
    "            # Calculate time since last frame was processed\n",
    "            curr_time = time.time()\n",
    "            time_since_last_frame = curr_time - prev_time\n",
    "            # Calculate sleep time based on desired FPS and moving average\n",
    "            time_to_wait = frame_time - time_since_last_frame\n",
    "            # Calculate sleep time to adjust to target frame time\n",
    "            sleep_time = max(time_to_wait - moving_avg_duration, 0)\n",
    "            time.sleep(sleep_time)\n",
    "            prev_time = time.time()\n",
    "            times.append(prev_time - start_time)\n",
    "            if cudacanvas.should_close() or not ret:\n",
    "                break\n",
    "\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)  # Total number of frames in the video\n",
    "    total_time = sum(times)  # Total processing time, assuming 'times' list is populated per frame as shown previously\n",
    "\n",
    "    # Calculate and print the rendering FPS\n",
    "    rendering_fps = total_frames / total_time\n",
    "    print(f\"Rendering FPS: {rendering_fps}\")\n",
    "    print(f\"Original FPS: {fps}\")\n",
    "\n",
    "    # Calculate and print the video length in seconds\n",
    "    video_length = total_frames / fps  # Original video's FPS used for length calculation\n",
    "    print(f\"Video Length: {video_length} seconds\")\n",
    "    print(f\"Original Video Length: {total_frames / fps} seconds\")\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# testing\n",
    "# upscale_video('test_videos/rabbit.mp4', model, transform = transform, out_video_path=\"output_video.mp4\", evaluate_mode = True)\n",
    "upscale_video('test_videos/rabbit.mp4', model, transform = transform, evaluate_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from PIL import Image\n",
    "\n",
    "def evaluate_upscaling_performance(input_video_path, ground_truth_video_path, model, transform=None, device=torch.device('cuda')):\n",
    "    input_cap = cv2.VideoCapture(input_video_path)\n",
    "    gt_cap = cv2.VideoCapture(ground_truth_video_path)\n",
    "    \n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    \n",
    "    while True:\n",
    "        ret_input, input_frame = input_cap.read()\n",
    "        ret_gt, gt_frame = gt_cap.read()\n",
    "        \n",
    "        if not ret_input or not ret_gt:\n",
    "            break\n",
    "\n",
    "        input_frame_rgb = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "        gt_frame_rgb = cv2.cvtColor(gt_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if transform:\n",
    "            input_frame_tensor = transform(input_frame_rgb).unsqueeze(0).to(device)\n",
    "        else:\n",
    "            input_frame_tensor = to_tensor(input_frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame = model(input_frame_tensor)\n",
    "            upscaled_frame = upscaled_frame.squeeze(0).cpu()\n",
    "\n",
    "        upscaled_frame_pil = to_pil_image(upscaled_frame)\n",
    "        upscaled_frame_resized_pil = upscaled_frame_pil.resize((gt_frame_rgb.shape[1], gt_frame_rgb.shape[0]), Image.BICUBIC)\n",
    "        upscaled_frame_resized = np.array(upscaled_frame_resized_pil)\n",
    "\n",
    "        frame_psnr = compare_psnr(gt_frame_rgb, upscaled_frame_resized, data_range=255)\n",
    "\n",
    "        # Ensure win_size is valid and does not exceed the image dimensions\n",
    "        win_size = 3  # Minimum viable window size for SSIM that still allows for a meaningful comparison\n",
    "        \n",
    "        frame_ssim = compare_ssim(gt_frame_rgb, upscaled_frame_resized, multichannel=True, data_range=255, win_size=win_size)\n",
    "        \n",
    "        psnr_values.append(frame_psnr)\n",
    "        ssim_values.append(frame_ssim)\n",
    "\n",
    "    input_cap.release()\n",
    "    gt_cap.release()\n",
    "\n",
    "    avg_psnr = np.mean(psnr_values)\n",
    "    avg_ssim = np.mean(ssim_values)\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_upscaling_performance('path_to_low_res_video.mp4', 'path_to_high_res_video.mp4', model, transform=None, device=torch.device('cuda'))\n",
    "evaluate_upscaling_performance('test_videos\\production720.mp4', 'test_videos\\production2160.mp4', model, transform=None, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average FPS for 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input frame size = torch.Size([1, 3, 720, 1280])\n",
      "Output frame size = torch.Size([1, 3, 2160, 3840])\n",
      "Average Time per frame = 4.914951801300049 ms\n",
      "Average FPS = 203.46079482111932 FPS\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 3, 720, 1280).to(device)\n",
    "times = []\n",
    "for i in range(1000):\n",
    "  torch.cuda.synchronize()\n",
    "  start = time.time()\n",
    "  with torch.no_grad():\n",
    "    pred = model(noise)\n",
    "    pred = torch.clamp(pred, 0, 1)\n",
    "  torch.cuda.synchronize()\n",
    "  end = time.time() - start\n",
    "  times.append(end)\n",
    "\n",
    "# plt.imshow(pred.squeeze().cpu().numpy().transpose(1, 2, 0))\n",
    "avg_time = np.mean(times)\n",
    "\n",
    "print(\"Input frame size =\", noise.shape)\n",
    "print(\"Output frame size =\", pred.shape)\n",
    "print(\"Average Time per frame =\", 1000*avg_time, \"ms\")\n",
    "print(\"Average FPS =\", 1/avg_time, \"FPS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "766-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
