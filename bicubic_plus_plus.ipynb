{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import cudacanvas\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bicubic Plus Plus Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bicubic_plus_plus(\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv_out): Conv2d(32, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (Depth2Space): PixelShuffle(upscale_factor=6)\n",
       "  (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bicubic_plus_plus(nn.Module):\n",
    "    \"\"\"\n",
    "    Bicuic Plus Plus model. Adapted from Aselsan Researach group.\n",
    "    - Pretrained weights from their github repository.\n",
    "    - https://github.com/aselsan-research-imaging-team/bicubic-plusplus \n",
    "    \"\"\"\n",
    "    def __init__(self, sr_rate=3):\n",
    "        super(Bicubic_plus_plus, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_out = nn.Conv2d(32, (2*sr_rate)**2 * 3, kernel_size=3, padding=1, bias=False)\n",
    "        self.Depth2Space = nn.PixelShuffle(2*sr_rate)\n",
    "        self.act = nn.LeakyReLU(inplace=True, negative_slope=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv0(x)\n",
    "        x0 = self.act(x0)\n",
    "        x1 = self.conv1(x0)\n",
    "        x1 = self.act(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.act(x2) + x0\n",
    "        y = self.conv_out(x2)\n",
    "        y = self.Depth2Space(y)\n",
    "        return y\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Bicubic_plus_plus().to(device)\n",
    "model.load_state_dict(torch.load('bicubic_pp_x3.pth'))\n",
    "model.eval()\n",
    "# Print number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get cursor position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse callback function to update cursor position\n",
    "def update_cursor_position(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x, cursor_y = x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform to be applied to frames\n",
    "# Currently only transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def upscale_video(video_path, model, transform = None, out_video_path = None, evaluate_mode = False):\n",
    "    \"\"\"\n",
    "    Upscale a video 3x by using bicubic plus plus model\n",
    "    - video_path: path to the video\n",
    "    - model: bicubic plus plus model\n",
    "    - transform: transform to be applied to frames\n",
    "    - out_video_path: path to the output video (only if evaluate_mode is True)\n",
    "    - evaluate_mode: if True, model is used to write the video to storage so that it can be evaluated.\n",
    "    - evaluate mode is slow due to GPu -> CPU transfer overhead\n",
    "\n",
    "    - Output: Upscaled Video feed or File storage if in evaluate mode \n",
    "    \"\"\"\n",
    "    # Set CUDA device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_width*3, frame_height*3))\n",
    "\n",
    "\n",
    "    # Set up cudacanvas window for renders\n",
    "    if not evaluate_mode:\n",
    "        white_screen = torch.ones((3, frame_height, frame_width*2)).to(device)\n",
    "        cudacanvas.set_image(white_screen)\n",
    "        cudacanvas.create_window()\n",
    "\n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        elapsed_time = 0\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_downsampled = cv2.resize(frame, (int(frame.shape[1] / 3), int(frame.shape[0] / 3))) \n",
    "        \n",
    "        # Convert frame to RGB and apply transform\n",
    "        frame_rgb = frame_downsampled\n",
    "        frame_rgb = cv2.cvtColor(frame_rgb, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        frame_bicubic = cv2.resize(frame_rgb, (frame_width, frame_height))\n",
    "        # frame_bicubic = cv2.cvtColor(frame_bicubic, cv2.COLOR_BGR2RGB)\n",
    "        frame_bicubic = transform(frame_bicubic).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_tensor = model(frame_tensor)\n",
    "            upscaled_frame_tensor = torch.clamp(upscaled_frame_tensor, 0, 1)\n",
    "        \n",
    "        # print(frame_downsampled.shape, frame_bicubic.shape, frame_tensor.shape, upscaled_frame_tensor.shape)\n",
    "        \n",
    "        # Write the upscaled frame to output video file if in evaluate mode\n",
    "        if evaluate_mode:\n",
    "            # Convert tensor back to numpy array\n",
    "            upscaled_frame = (upscaled_frame_tensor.squeeze().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "            upscaled_frame = cv2.cvtColor(upscaled_frame, cv2.COLOR_RGB2BGR)\n",
    "            # cv2.imshow('Upscaled Frame', upscaled_frame)\n",
    "            # # Write upscaled frame to output video\n",
    "            output_video.write(upscaled_frame)\n",
    "        \n",
    "        # If no evaluation, just output using cudacanvas\n",
    "        else:\n",
    "            cudacanvas.render()\n",
    "            # Concatenate frame and upscaled frame\n",
    "            combine = torch.concat([frame_bicubic, upscaled_frame_tensor], dim = -1)\n",
    "            cudacanvas.set_image(combine.squeeze())\n",
    "            if cudacanvas.should_close():\n",
    "                break\n",
    "        \n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        if evaluate_mode:\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# testing\n",
    "video_path = 'test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4' \n",
    "upscale_video(video_path, model, transform = transform, evaluate_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average FPS for 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input frame size = torch.Size([1, 3, 720, 1280])\n",
      "Output frame size = torch.Size([1, 3, 2160, 3840])\n",
      "Average Time per frame = 8.745447874069214 ms\n",
      "Average FPS = 114.34520157224433 FPS\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 3, 720, 1280).to(device)\n",
    "times = []\n",
    "for i in range(1000):\n",
    "  torch.cuda.synchronize()\n",
    "  start = time.time()\n",
    "  with torch.no_grad():\n",
    "    pred = model(noise)\n",
    "    pred = torch.clamp(pred, 0, 1)\n",
    "  torch.cuda.synchronize()\n",
    "  end = time.time() - start\n",
    "  times.append(end)\n",
    "\n",
    "# plt.imshow(pred.squeeze().cpu().numpy().transpose(1, 2, 0))\n",
    "avg_time = np.mean(times)\n",
    "\n",
    "print(\"Input frame size =\", noise.shape)\n",
    "print(\"Output frame size =\", pred.shape)\n",
    "print(\"Average Time per frame =\", 1000*avg_time, \"ms\")\n",
    "print(\"Average FPS =\", 1/avg_time, \"FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Timings\n",
    "- Uncomment each line to test individual transfer latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time (ms): 15.062652192674243\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "tot_time = 0\n",
    "\n",
    "# input tensor (360p)\n",
    "frame_tensor_cpu = torch.randn(1,3,960,720)\n",
    "frame_tensor_gpu = frame_tensor_cpu.to('cuda')\n",
    "frame_tensor_cpu_3x = torch.randn(1,3,2160,3840)\n",
    "frame_tensor_gpu_3x = frame_tensor_cpu_3x.to('cuda')\n",
    "frame_tensor_shared = frame_tensor_cpu_3x.pin_memory()\n",
    "shared_ref = torch.zeros(1,3,2160,3840).pin_memory()\n",
    "\n",
    "for i in range(1000):\n",
    "    st = time.time()\n",
    "    # frame_tensor_cpu.to('cuda') # 1.4 ms - normal cpu to gpu / 24.240\n",
    "    # frame_tensor_shared.to('cuda') # 9 ms - pinned cpu to gpu\n",
    "    # shared_ref[:] = frame_tensor_cpu_3x # 14.26 ms - normal cpu to pinned cpu\n",
    "    # shared_ref[:] = frame_tensor_gpu_3x # 8.07 ms - gpu to pinned cpu\n",
    "    # shared_ref.to('cpu') # 0.001 ms\n",
    "    frame_tensor_gpu_3x.to('cpu') # 16.12 ms - gpu to normal cpu\n",
    "    \n",
    "    tot_time += time.time() - st\n",
    "print('Average time (ms):', tot_time/i*1000)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Metrics\n",
    "- PSNR\n",
    "- SSIM\n",
    "- Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties:\n",
      "Frame width: 3840\n",
      "Frame height: 2160\n",
      "FPS: 30.00101354775499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_6496\\372167005.py:102: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
      "  psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.29567274080101 40.427541713214936 0.8155311144817291 0.9857818057670306 0.0 0.015794754028320312\n",
      "43.68689957231816 40.63730226354383 0.8169425584459106 0.98642192523354 0.0 0.03543710708618164\n",
      "43.83924868755939 40.73180058732581 0.8155399466915778 0.9864480328324094 0.0 0.1671442985534668\n",
      "43.83541550455777 40.72340917135741 0.8133725763913162 0.9863034814045518 0.0 0.02533411979675293\n",
      "44.01337951038991 40.78098481045388 0.8135616657382485 0.98638831772638 0.0 0.0\n",
      "Average PSNR (bicubic): 43.73412320312524\n",
      "Average PSNR (SR): 40.660207709179176\n",
      "Average SSIM (bicubic): 0.8149895723497564\n",
      "Average SSIM (SR): 0.9862687125927824\n",
      "Average inference time (bicubic): 0.0\n",
      "Average inference time (SR): 0.048742055892944336\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def evaluate_model(video_path, model, crop_size = [1920, 1080], upscale_factor = 3, n_samples = 10, transform = None):\n",
    "    \"\"\"\n",
    "    - This function samples a random area of 'crop_size' from the video. \n",
    "    - This is then downsampled by 3x and then upscaled back to 'crop_size'\n",
    "    - This is then compared to the original cropped frame\n",
    "    - The baseline is the regular bicubic upsampling\n",
    "\n",
    "    Inputs:\n",
    "    - video_path: path to the test 4k video\n",
    "    - model: Super res model\n",
    "    - n_samples: number of samples to evaluate\n",
    "    - transform: transform to use\n",
    "\n",
    "    Outputs:\n",
    "    - PSNR: Average Peak Signal to Noise Ratio\n",
    "    - SSIM: Average Structural Similarity Index\n",
    "    - infer_time: Average inference time\n",
    "    \"\"\"\n",
    "    # Get device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(\"Video properties:\")\n",
    "    print(\"Frame width:\", frame_width)\n",
    "    print(\"Frame height:\", frame_height)\n",
    "    print(\"FPS:\", fps)\n",
    "\n",
    "    # Read and process n_samples of frames\n",
    "    n = 0\n",
    "    psnr_bicubic_list = []\n",
    "    psnr_sr_list = []\n",
    "    ssim_bicubic_list = []\n",
    "    ssim_sr_list = []\n",
    "    infer_time_bicubic_list = []\n",
    "    infer_time_sr_list = []\n",
    "\n",
    "    while True and n < n_samples:\n",
    "        # Read frame \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if np.amax(frame) == 0 and np.amin(frame) == 0:\n",
    "            continue\n",
    "        n += 1\n",
    "        # if n == 1:\n",
    "        #     continue\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        crop_width, crop_height = crop_size\n",
    "        # Get cropped region of frame\n",
    "        x_start = random.randint(0, frame_width - crop_width)\n",
    "        y_start = random.randint(0, frame_height - crop_height)\n",
    "        x_end = x_start + crop_width\n",
    "        y_end = y_start + crop_height\n",
    "\n",
    "        \n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Downsample frame\n",
    "        downsampled_frame = cv2.resize(cropped_frame, (int(cropped_frame.shape[1] / upscale_factor), int(cropped_frame.shape[0] / upscale_factor)))\n",
    "\n",
    "        # Upsample frame\n",
    "        torch.cuda.synchronize()\n",
    "        time.time()\n",
    "        upscaled_frame_bicubic = cv2.resize(downsampled_frame, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_bicubic = time.time() - time.time()\n",
    "        # print(frame.shape, cropped_frame.shape, downsampled_frame.shape, upscaled_frame_bicubic.shape)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(downsampled_frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_sr = time.time() - start\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_bicubic = compare_psnr(cropped_frame, upscaled_frame_bicubic)\n",
    "        psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n",
    "\n",
    "        # Calculate SSIM\n",
    "        ssim_bicubic = compare_ssim(cropped_frame, upscaled_frame_bicubic, channel_axis=-1, data_range=1, multichannel=True)\n",
    "        ssim_sr = compare_ssim(cropped_frame/255, upscaled_frame_sr, channel_axis=-1, data_range=1, multichannel=True)\n",
    "\n",
    "        print(psnr_bicubic, psnr_sr, ssim_bicubic, ssim_sr, infer_time_bicubic, infer_time_sr)\n",
    "\n",
    "        psnr_bicubic_list.append(psnr_bicubic)\n",
    "        psnr_sr_list.append(psnr_sr)\n",
    "        ssim_bicubic_list.append(ssim_bicubic)\n",
    "        ssim_sr_list.append(ssim_sr)\n",
    "        infer_time_bicubic_list.append(infer_time_bicubic)\n",
    "        infer_time_sr_list.append(infer_time_sr)\n",
    "\n",
    "        # Display the upscaled frame by concatenating the original and upscaled frames\n",
    "        # top = np.concatenate((cropped_frame/255, cropped_frame/255), axis=1)\n",
    "        # bottom = np.concatenate((upscaled_frame_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        # combined = np.concatenate((top, bottom), axis=0)\n",
    "        # cv2.imshow('frame', combined)\n",
    "        \n",
    "        # # cv2.imshow('frame', upscaled_frame_sr)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "        \n",
    "\n",
    "    # Calculate average PSNR and SSIM only for values that are not Nan or Inf\n",
    "    psnr_bicubic_list = [psnr for psnr in psnr_bicubic_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    psnr_sr_list = [psnr for psnr in psnr_sr_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    ssim_bicubic_list = [ssim for ssim in ssim_bicubic_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    ssim_sr_list = [ssim for ssim in ssim_sr_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    infer_time_bicubic_list = [infer_time for infer_time in infer_time_bicubic_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "    infer_time_sr_list = [infer_time for infer_time in infer_time_sr_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "\n",
    "    avg_psnr_bicubic = np.mean(psnr_bicubic_list)\n",
    "    avg_psnr_sr = np.mean(psnr_sr_list)\n",
    "    avg_ssim_bicubic = np.mean(ssim_bicubic_list)\n",
    "    avg_ssim_sr = np.mean(ssim_sr_list)\n",
    "    avg_infer_time_bicubic = np.mean(infer_time_bicubic_list)\n",
    "    avg_infer_time_sr = np.mean(infer_time_sr_list)\n",
    "\n",
    "\n",
    "    return avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr\n",
    "\n",
    "\n",
    "video_path = \"./test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4\"\n",
    "avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr = evaluate_model(video_path, model, transform=transform, n_samples=5\n",
    "                                                                                                                         , crop_size=[3840,2160])        \n",
    "print(\"Average PSNR (bicubic):\", avg_psnr_bicubic)\n",
    "print(\"Average PSNR (SR):\", avg_psnr_sr)\n",
    "print(\"Average SSIM (bicubic):\", avg_ssim_bicubic)\n",
    "print(\"Average SSIM (SR):\", avg_ssim_sr)\n",
    "print(\"Average inference time (bicubic):\", avg_infer_time_bicubic)\n",
    "print(\"Average inference time (SR):\", avg_infer_time_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "766-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
