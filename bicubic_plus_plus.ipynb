{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import cudacanvas\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bicubic Plus Plus Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bicubic_plus_plus(\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (conv_out): Conv2d(32, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (Depth2Space): PixelShuffle(upscale_factor=6)\n",
       "  (act): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bicubic_plus_plus(nn.Module):\n",
    "    \"\"\"\n",
    "    Bicuic Plus Plus model. Adapted from Aselsan Researach group.\n",
    "    - Pretrained weights from their github repository.\n",
    "    - https://github.com/aselsan-research-imaging-team/bicubic-plusplus \n",
    "    \"\"\"\n",
    "    def __init__(self, sr_rate=3):\n",
    "        super(Bicubic_plus_plus, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv_out = nn.Conv2d(32, (2*sr_rate)**2 * 3, kernel_size=3, padding=1, bias=False)\n",
    "        self.Depth2Space = nn.PixelShuffle(2*sr_rate)\n",
    "        self.act = nn.LeakyReLU(inplace=True, negative_slope=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv0(x)\n",
    "        x0 = self.act(x0)\n",
    "        x1 = self.conv1(x0)\n",
    "        x1 = self.act(x1)\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.act(x2) + x0\n",
    "        y = self.conv_out(x2)\n",
    "        y = self.Depth2Space(y)\n",
    "        return y\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Bicubic_plus_plus().to(device)\n",
    "model.load_state_dict(torch.load('bicubic_pp_x3.pth'))\n",
    "model.eval()\n",
    "# Print number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get cursor position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mouse callback function to update cursor position\n",
    "def update_cursor_position(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x, cursor_y = x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform to be applied to frames\n",
    "# Currently only transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def upscale_video(video_path, model, transform = None, out_video_path = None, evaluate_mode = False):\n",
    "    \"\"\"\n",
    "    Upscale a video 3x by using bicubic plus plus model\n",
    "    - video_path: path to the video\n",
    "    - model: bicubic plus plus model\n",
    "    - transform: transform to be applied to frames\n",
    "    - out_video_path: path to the output video (only if evaluate_mode is True)\n",
    "    - evaluate_mode: if True, model is used to write the video to storage so that it can be evaluated.\n",
    "    - evaluate mode is slow due to GPu -> CPU transfer overhead\n",
    "\n",
    "    - Output: Upscaled Video feed or File storage if in evaluate mode \n",
    "    \"\"\"\n",
    "    # Set CUDA device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define codec and VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(out_video_path, fourcc, fps, (frame_width*3, frame_height*3))\n",
    "\n",
    "\n",
    "    # Set up cudacanvas window for renders\n",
    "    if not evaluate_mode:\n",
    "        white_screen = torch.ones((3, 1080, 1920)).to(device)\n",
    "        cudacanvas.set_image(white_screen)\n",
    "        cudacanvas.create_window()\n",
    "\n",
    "    # Process each frame\n",
    "    while cap.isOpened():\n",
    "        elapsed_time = 0\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_downsampled = cv2.resize(frame, (int(frame.shape[1] / 6), int(frame.shape[0] / 6))) \n",
    "        \n",
    "        # Convert frame to RGB and apply transform\n",
    "        frame_rgb = frame_downsampled\n",
    "        frame_rgb = cv2.cvtColor(frame_rgb, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        frame_bicubic = cv2.resize(frame_rgb, (frame_downsampled.shape[1] * 3, frame_downsampled.shape[0] * 3))\n",
    "        # frame_bicubic = cv2.cvtColor(frame_bicubic, cv2.COLOR_BGR2RGB)\n",
    "        frame_bicubic = transform(frame_bicubic).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_tensor = model(frame_tensor)\n",
    "            upscaled_frame_tensor = torch.clamp(upscaled_frame_tensor, 0, 1)\n",
    "        \n",
    "        # print(frame_downsampled.shape, frame_bicubic.shape, frame_tensor.shape, upscaled_frame_tensor.shape)\n",
    "        \n",
    "        # Write the upscaled frame to output video file if in evaluate mode\n",
    "        if evaluate_mode:\n",
    "            # Convert tensor back to numpy array\n",
    "            upscaled_frame = (upscaled_frame_tensor.squeeze().cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "            upscaled_frame = cv2.cvtColor(upscaled_frame, cv2.COLOR_RGB2BGR)\n",
    "            # cv2.imshow('Upscaled Frame', upscaled_frame)\n",
    "            # # Write upscaled frame to output video\n",
    "            output_video.write(upscaled_frame)\n",
    "        \n",
    "        # If no evaluation, just output using cudacanvas\n",
    "        else:\n",
    "            cudacanvas.render()\n",
    "            # Concatenate frame and upscaled frame\n",
    "            combine = torch.concat([frame_bicubic, upscaled_frame_tensor], dim = -1)\n",
    "            cudacanvas.set_image(upscaled_frame_tensor.squeeze())\n",
    "            if cudacanvas.should_close():\n",
    "                break\n",
    "        \n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "        if evaluate_mode:\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    output_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# testing\n",
    "video_path = 'test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4' \n",
    "upscale_video(video_path, model, transform = transform, evaluate_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average FPS for 1000 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input frame size = torch.Size([1, 3, 720, 1280])\n",
      "Output frame size = torch.Size([1, 3, 2160, 3840])\n",
      "Average Time per frame = 8.938189506530762 ms\n",
      "Average FPS = 111.87948065649557 FPS\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn(1, 3, 720, 1280).to(device)\n",
    "times = []\n",
    "for i in range(1000):\n",
    "  torch.cuda.synchronize()\n",
    "  start = time.time()\n",
    "  with torch.no_grad():\n",
    "    pred = model(noise)\n",
    "    pred = torch.clamp(pred, 0, 1)\n",
    "  torch.cuda.synchronize()\n",
    "  end = time.time() - start\n",
    "  times.append(end)\n",
    "\n",
    "# plt.imshow(pred.squeeze().cpu().numpy().transpose(1, 2, 0))\n",
    "avg_time = np.mean(times)\n",
    "\n",
    "print(\"Input frame size =\", noise.shape)\n",
    "print(\"Output frame size =\", pred.shape)\n",
    "print(\"Average Time per frame =\", 1000*avg_time, \"ms\")\n",
    "print(\"Average FPS =\", 1/avg_time, \"FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Timings\n",
    "- Uncomment each line to test individual transfer latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time (ms): 18.271894426317186\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "tot_time = 0\n",
    "\n",
    "# input tensor (360p)\n",
    "frame_tensor_cpu = torch.randn(1,3,960,720)\n",
    "frame_tensor_gpu = frame_tensor_cpu.to('cuda')\n",
    "frame_tensor_cpu_3x = torch.randn(1,3,2160,3840)\n",
    "frame_tensor_gpu_3x = frame_tensor_cpu_3x.to('cuda')\n",
    "frame_tensor_shared = frame_tensor_cpu_3x.pin_memory()\n",
    "shared_ref = torch.zeros(1,3,2160,3840).pin_memory()\n",
    "\n",
    "for i in range(1000):\n",
    "    st = time.time()\n",
    "    # frame_tensor_cpu.to('cuda') # 1.4 ms - normal cpu to gpu / 24.240\n",
    "    # frame_tensor_shared.to('cuda') # 9 ms - pinned cpu to gpu\n",
    "    # shared_ref[:] = frame_tensor_cpu_3x # 14.26 ms - normal cpu to pinned cpu\n",
    "    # shared_ref[:] = frame_tensor_gpu_3x # 8.07 ms - gpu to pinned cpu\n",
    "    # shared_ref.to('cpu') # 0.001 ms\n",
    "    frame_tensor_gpu_3x.to('cpu') # 16.12 ms - gpu to normal cpu\n",
    "    \n",
    "    tot_time += time.time() - st\n",
    "print('Average time (ms):', tot_time/i*1000)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Metrics\n",
    "- PSNR\n",
    "- SSIM\n",
    "- Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties:\n",
      "Frame width: 3840\n",
      "Frame height: 2160\n",
      "FPS: 30.00101354775499\n",
      "(2160, 3840, 3) (1080, 1920, 3) (360, 640, 3) (1080, 1920, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\AppData\\Local\\Temp\\ipykernel_14344\\2129197455.py:102: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
      "  psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.233039205146866 43.041668964738456 0.7736065358068177 0.990475502655585 0.0 0.06435894966125488\n",
      "(2160, 3840, 3) (1080, 1920, 3) (360, 640, 3) (1080, 1920, 3)\n",
      "45.252899307606754 42.00075535799873 0.7883601524149534 0.9882298835724649 0.0 0.0\n",
      "(2160, 3840, 3) (1080, 1920, 3) (360, 640, 3) (1080, 1920, 3)\n",
      "44.79861084153396 41.16111115631601 0.8202942806327812 0.9861580371694559 0.0 0.0\n",
      "(2160, 3840, 3) (1080, 1920, 3) (360, 640, 3) (1080, 1920, 3)\n",
      "44.48726334903644 40.90666206568486 0.7843057242246845 0.9853495003841091 0.0 0.015615701675415039\n",
      "(2160, 3840, 3) (1080, 1920, 3) (360, 640, 3) (1080, 1920, 3)\n",
      "44.23466818718295 41.271178730566504 0.7814210910271369 0.98870947664572 0.0 0.003679513931274414\n",
      "Average PSNR (bicubic): 45.00129617810139\n",
      "Average PSNR (SR): 41.676275255060915\n",
      "Average SSIM (bicubic): 0.7895975568212747\n",
      "Average SSIM (SR): 0.9877844800854669\n",
      "Average inference time (bicubic): 0.0\n",
      "Average inference time (SR): 0.016730833053588866\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def evaluate_model(video_path, model, crop_size = [1920, 1080], upscale_factor = 3, n_samples = 10, transform = None):\n",
    "    \"\"\"\n",
    "    - This function samples a random area of 'crop_size' from the video. \n",
    "    - This is then downsampled by 3x and then upscaled back to 'crop_size'\n",
    "    - This is then compared to the original cropped frame\n",
    "    - The baseline is the regular bicubic upsampling\n",
    "\n",
    "    Inputs:\n",
    "    - video_path: path to the test 4k video\n",
    "    - model: Super res model\n",
    "    - n_samples: number of samples to evaluate\n",
    "    - transform: transform to use\n",
    "\n",
    "    Outputs:\n",
    "    - PSNR: Average Peak Signal to Noise Ratio\n",
    "    - SSIM: Average Structural Similarity Index\n",
    "    - infer_time: Average inference time\n",
    "    \"\"\"\n",
    "    # Get device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(\"Video properties:\")\n",
    "    print(\"Frame width:\", frame_width)\n",
    "    print(\"Frame height:\", frame_height)\n",
    "    print(\"FPS:\", fps)\n",
    "\n",
    "    # Read and process n_samples of frames\n",
    "    n = 0\n",
    "    psnr_bicubic_list = []\n",
    "    psnr_sr_list = []\n",
    "    ssim_bicubic_list = []\n",
    "    ssim_sr_list = []\n",
    "    infer_time_bicubic_list = []\n",
    "    infer_time_sr_list = []\n",
    "\n",
    "    while True and n < n_samples:\n",
    "        # Read frame \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if np.amax(frame) == 0 and np.amin(frame) == 0:\n",
    "            continue\n",
    "        n += 1\n",
    "        # if n == 1:\n",
    "        #     continue\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        crop_width, crop_height = crop_size\n",
    "        # Get cropped region of frame\n",
    "        x_start = random.randint(0, frame_width - crop_width)\n",
    "        y_start = random.randint(0, frame_height - crop_height)\n",
    "        x_end = x_start + crop_width\n",
    "        y_end = y_start + crop_height\n",
    "\n",
    "        \n",
    "\n",
    "        # Crop the frame\n",
    "        cropped_frame = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Downsample frame\n",
    "        downsampled_frame = cv2.resize(cropped_frame, (int(cropped_frame.shape[1] / upscale_factor), int(cropped_frame.shape[0] / upscale_factor)))\n",
    "\n",
    "        # Upsample frame\n",
    "        torch.cuda.synchronize()\n",
    "        time.time()\n",
    "        upscaled_frame_bicubic = cv2.resize(downsampled_frame, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_bicubic = time.time() - time.time()\n",
    "        print(frame.shape, cropped_frame.shape, downsampled_frame.shape, upscaled_frame_bicubic.shape)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(downsampled_frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        # Perform super-resolution on the frame\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "        torch.cuda.synchronize()\n",
    "        infer_time_sr = time.time() - start\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Calculate PSNR\n",
    "        psnr_bicubic = compare_psnr(cropped_frame, upscaled_frame_bicubic)\n",
    "        psnr_sr = compare_psnr(cropped_frame/255, upscaled_frame_sr)\n",
    "\n",
    "        # Calculate SSIM\n",
    "        ssim_bicubic = compare_ssim(cropped_frame, upscaled_frame_bicubic, channel_axis=-1, data_range=1, multichannel=True)\n",
    "        ssim_sr = compare_ssim(cropped_frame/255, upscaled_frame_sr, channel_axis=-1, data_range=1, multichannel=True)\n",
    "\n",
    "        print(psnr_bicubic, psnr_sr, ssim_bicubic, ssim_sr, infer_time_bicubic, infer_time_sr)\n",
    "\n",
    "        psnr_bicubic_list.append(psnr_bicubic)\n",
    "        psnr_sr_list.append(psnr_sr)\n",
    "        ssim_bicubic_list.append(ssim_bicubic)\n",
    "        ssim_sr_list.append(ssim_sr)\n",
    "        infer_time_bicubic_list.append(infer_time_bicubic)\n",
    "        infer_time_sr_list.append(infer_time_sr)\n",
    "\n",
    "        # Display the upscaled frame by concatenating the original and upscaled frames\n",
    "        # top = np.concatenate((cropped_frame/255, cropped_frame/255), axis=1)\n",
    "        # bottom = np.concatenate((upscaled_frame_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        # combined = np.concatenate((top, bottom), axis=0)\n",
    "        # cv2.imshow('frame', combined)\n",
    "        \n",
    "        # # cv2.imshow('frame', upscaled_frame_sr)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "        \n",
    "\n",
    "    # Calculate average PSNR and SSIM only for values that are not Nan or Inf\n",
    "    psnr_bicubic_list = [psnr for psnr in psnr_bicubic_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    psnr_sr_list = [psnr for psnr in psnr_sr_list if not np.isnan(psnr) and not np.isinf(psnr)]\n",
    "    ssim_bicubic_list = [ssim for ssim in ssim_bicubic_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    ssim_sr_list = [ssim for ssim in ssim_sr_list if not np.isnan(ssim) and not np.isinf(ssim)]\n",
    "    infer_time_bicubic_list = [infer_time for infer_time in infer_time_bicubic_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "    infer_time_sr_list = [infer_time for infer_time in infer_time_sr_list if not np.isnan(infer_time) and not np.isinf(infer_time)]\n",
    "\n",
    "    avg_psnr_bicubic = np.mean(psnr_bicubic_list)\n",
    "    avg_psnr_sr = np.mean(psnr_sr_list)\n",
    "    avg_ssim_bicubic = np.mean(ssim_bicubic_list)\n",
    "    avg_ssim_sr = np.mean(ssim_sr_list)\n",
    "    avg_infer_time_bicubic = np.mean(infer_time_bicubic_list)\n",
    "    avg_infer_time_sr = np.mean(infer_time_sr_list)\n",
    "\n",
    "\n",
    "    return avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr\n",
    "\n",
    "\n",
    "video_path = \"./test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4\"\n",
    "avg_psnr_bicubic, avg_psnr_sr, avg_ssim_bicubic, avg_ssim_sr, avg_infer_time_bicubic, avg_infer_time_sr = evaluate_model(video_path, model, transform=transform, n_samples=5\n",
    "                                                                                                                         , crop_size=[1920,1080]\n",
    "                                                                                                                         )        \n",
    "print(\"Average PSNR (bicubic):\", avg_psnr_bicubic)\n",
    "print(\"Average PSNR (SR):\", avg_psnr_sr)\n",
    "print(\"Average SSIM (bicubic):\", avg_ssim_bicubic)\n",
    "print(\"Average SSIM (SR):\", avg_ssim_sr)\n",
    "print(\"Average inference time (bicubic):\", avg_infer_time_bicubic)\n",
    "print(\"Average inference time (SR):\", avg_infer_time_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sample image for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./test_videos/2022-Formula1-Aston-Martin-AMR22-006-2160.jpg\"\n",
    "img_path = \"test_videos/4K ULtra HD ｜ SAMSUNG UHD Demo׃ LED TV [R3GfuzLMPkA].mp4\"\n",
    "# image = cv2.imread(img_path)\n",
    "cap = cv2.VideoCapture(img_path)\n",
    "\n",
    "cursor_x = -1\n",
    "cursor_y = -1\n",
    "drawing = False\n",
    "\n",
    "# Mouse callback function\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x = x\n",
    "        cursor_y = y\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "\n",
    "cv2.namedWindow('BBoxWindow')\n",
    "cv2.namedWindow('Cropped frame')\n",
    "# cv2.namedWindow(\"SR Window\")\n",
    "cv2.setMouseCallback('BBoxWindow', mouse_callback)\n",
    "\n",
    "bb_size = [270,180]\n",
    "cropped_image_bicubic = np.zeros((bb_size[1]*3, bb_size[0]*3, 3))\n",
    "combined = np.zeros((bb_size[1]*3*2, bb_size[0]*3, 3))\n",
    "upscaled_frame_sr = np.zeros((bb_size[1]*3, bb_size[0]*3, 3))\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    # image = cv2.resize(image, (1920,1080))\n",
    "    if not ret:\n",
    "        break\n",
    "    # Draw bounding box based on cursor position\n",
    "    if cursor_x != -1 and cursor_y != -1:\n",
    "        # top_left = (max(0,cursor_x - bb_size[0]//2), max(0,cursor_y - bb_size[1]//2))\n",
    "        # bottom_right = (min(image.shape[0],cursor_x + bb_size[0]//2), min(image.shape[1], cursor_y + bb_size[1]//2))\n",
    "        \n",
    "        top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "        bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "        \n",
    "        # crop image only for the bounding box region\n",
    "        if top_left[0] >= 0 and top_left[1] >= 0 and bottom_right[0] < image.shape[1] and bottom_right[1] < image.shape[0]:\n",
    "            cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            cropped_image_bicubic = cv2.resize(cropped_image, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Stack horizontally\n",
    "        combined = np.concatenate((cropped_image_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        \n",
    "        # image_copy = image.copy()\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Cropped frame', combined)\n",
    "    cv2.imshow(\"SR Window\", upscaled_frame_sr)\n",
    "    \n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Single image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./test_videos/2022-Formula1-Aston-Martin-AMR22-006-2160.jpg\"\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "cursor_x = -1\n",
    "cursor_y = -1\n",
    "save = False\n",
    "\n",
    "# Mouse callback function\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global cursor_x, cursor_y\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        cursor_x = x\n",
    "        cursor_y = y\n",
    "    elif event == cv2.EVENT_LBUTTONDOWN:\n",
    "        save = True\n",
    "\n",
    "cv2.namedWindow('BBoxWindow')\n",
    "cv2.namedWindow('Result frame')\n",
    "# cv2.namedWindow(\"SR Window\")\n",
    "cv2.setMouseCallback('BBoxWindow', mouse_callback)\n",
    "\n",
    "bb_size = [270,180]\n",
    "cropped_image_bicubic = np.zeros((bb_size[1]*3, bb_size[0]*3, 3))\n",
    "combined = np.zeros((bb_size[1]*3*2, bb_size[0]*3, 3))\n",
    "upscaled_frame_sr = np.zeros((bb_size[1]*3, bb_size[0]*3, 3))\n",
    "\n",
    "while True:\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # Draw bounding box based on cursor position\n",
    "    if cursor_x != -1 and cursor_y != -1:\n",
    "        # top_left = (max(0,cursor_x - bb_size[0]//2), max(0,cursor_y - bb_size[1]//2))\n",
    "        # bottom_right = (min(image.shape[0],cursor_x + bb_size[0]//2), min(image.shape[1], cursor_y + bb_size[1]//2))\n",
    "        \n",
    "        top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "        bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "        \n",
    "        # crop image only for the bounding box region\n",
    "        if top_left[0] >= 0 and top_left[1] >= 0 and bottom_right[0] < image.shape[1] and bottom_right[1] < image.shape[0]:\n",
    "            cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            cropped_image_bicubic = cv2.resize(cropped_image, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert frame to tensor\n",
    "        frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            upscaled_frame_sr = model(frame_tensor)\n",
    "            upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "        # Convert tensor back to numpy array\n",
    "        upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "        upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Stack horizontally\n",
    "        combined = np.concatenate((cropped_image_bicubic/255, upscaled_frame_sr), axis=1)\n",
    "        \n",
    "        # image_copy = image.copy()\n",
    "        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Cropped frame', combined)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Results (Midterm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"test_videos/input_image.png\"\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "# Get ROI\n",
    "cursor_x = 650\n",
    "cursor_y = 252\n",
    "\n",
    "bb_size = [135,90]\n",
    "\n",
    "top_left = (cursor_x - bb_size[0]//2, cursor_y - bb_size[1]//2)\n",
    "bottom_right = (cursor_x + bb_size[0]//2 , cursor_y + bb_size[1]//2)\n",
    "\n",
    "cropped_image = image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "cropped_image_bicubic = cv2.resize(cropped_image, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Convert frame to tensor\n",
    "frame_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "frame_tensor = transform(frame_rgb).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    upscaled_frame_sr = model(frame_tensor)\n",
    "    upscaled_frame_sr = torch.clamp(upscaled_frame_sr, 0, 1)\n",
    "\n",
    "# Convert tensor back to numpy array\n",
    "upscaled_frame_sr = (upscaled_frame_sr.squeeze().cpu().numpy().transpose(1, 2, 0))# * 255).astype(np.uint8)\n",
    "upscaled_frame_sr = cv2.cvtColor(upscaled_frame_sr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# image_copy = image.copy()\n",
    "cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imwrite(\"Results/bird_frame.jpg\", image)\n",
    "# cv2.imwrite(\"Results/bird_bicubic_frame.jpg\", (cropped_image_bicubic).astype(np.uint8))\n",
    "# cv2.imwrite(\"Results/bird_upscaled_frame_sr_b++.jpg\", (upscaled_frame_sr*255).astype(np.uint8))\n",
    "\n",
    "while True:\n",
    "    # Display the imageq\n",
    "    cv2.imshow('BBoxWindow', image)\n",
    "    cv2.imshow('Result frame', upscaled_frame_sr)\n",
    "    cv2.imshow('Bicubic frame', cropped_image_bicubic)\n",
    "\n",
    "    \n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 402)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "877,402"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "766-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
